# 신경망 기초
# Perception in self-driving car

- Introduction of self-driving car
- Perception in self-driving car

---

## Introduction of self-driving car

- perception(computer vision, sensor fusion)외부 상황을 인지 → localization → path planning control
    - Perception
        - lane detection
        - pre-space detection ( 앞 쪽 부분에 차가 있는지 없는지)
        - Sensor-fusion
    - Localization
        - lane과 traffic sign들을 통해서 기존 가지고 있던 map과 matching
- Various sensor in self-driving car
    - Radar : 라디오파 이용 정밀도 떨어지지만, 가격쌈
    - Lader : 적외선 펄스를 사용한 물체 감지 및 거리 측정, 정밀도가 높으며 가격 비쌈
- 활용
    - ADAS, Parking assistance
    - Delivery robot, agv
- Visual Perception tasks
    - classification
    - object detection
    - semantic segmentation
    - instance segmentation
    - Depth/ distance estimation
    - object tracking

# Image Classification

- Introduction of image classification
- History of image classification
- Pytorch first step
- MNIST coding

---

## Image classification

- input : image → output : class 확률
- CNN을 가장 많이 씁니다만

## History of image classification


- alexnet : gpu로 연산을 병렬적으로 할 수 있게 되어서 결과적으로 좋아짐 ( Relu 사용)
- VGGNet : 16, 19 ,,, 3x3 conv 도입→ weight는 적어지고 성능은 좋아짐
- GoogLeNet: Inception module(여러가지 컨벌루션을 한번에 concat 해서 결과를 합침) , 1x1 conv
- ResNet(Kaiming He) : 파라미터 수가 많은 걸 보안한 논문 →동일한 웨이트들을 여러번 연산해서 실제 파라미터 수는 적되 모델 레이어 수는 깊어지는 효과를가져옴 /  Residual block , skip connection
    
    

### docker

https://docs.nvidia.com/deeplearning/frameworks/user-guide/index.html#runcont

→ docker version이 >19.03 에서 사용할 수 있다고 함 (파이토치 깔려있는 곳에서 바로 할 수 있다는! 강사님께서 만들어 두신 도커이미지파일을 통해)

### prepare coding env

1. Install docker on ubuntu
2. install nvidia-container toolkit to use NGC
3. pull the docker image
    
    ```cpp
    docker pull nvcr.io/nvidia/pytorch:21.12-py3
    ```
    
4. make docker container
    
    ```cpp
    docker run -it --gpus "device=0" -v /media/hdd/damin:/damin --name "damin_torch" nvcr.io/nvidia/pytorch:21.12-py3 /bin/bash
    ```
    

# PyTorch first step

- pytorch  : define-by-run
- tensorflow :  define / run → 1말고 2는 조금 달랐던 것 같은!
- https://news.hada.io/topic?id=5578
- JAX : https://modulabs.co.kr/blog/what-is-jax-flax/

- window conda setting
    
    

## Tensor

- 1D, 2D….. N-dimensions
- Array, Matrix 와 유사한 자료구조
- Input, Output of each layer in DL model
    
    
- conda 환경 생성
    
    ```bash
    conda create -n pytorch_py38 python=3.8
    ```
    

# Pratice 1

- 
- pratice 강의 25:15초에서 row, col 을 바꿔서 잘 못 말씀하신 걸까요?

    

# Practice 2

강의 한번 다시 듣기

https://school.programmers.co.kr/app/courses/16304/curriculum/lessons/153875

## MNIST

```python
import torch 
import torch.nn as nn
from turtle import down

from torchvision.datasets import MNIST
import torchvision.transforms as transforms
import argparse
import sys

def parse_args():
    parser = argparse.ArgumentParser(description = "MNIST")
    parser.add_argument("--mode", dest = "mode", help = "train / eval / test", default = "None", type = str)
    parser.add_argument("--download", dest = "download", help = "download MNIST", default = "False", type = bool)
    parser.add_argument("--output_dir", dest = "output_dir", help = "output directory", default = "/Users/1001l1000/Documents/Dev-Course/11-4./MNIST//output", type = str)
    parser.add_argument("--checkpoint", dest = "checkpoint", help = "checkpoint trained model", default = "None", type = str)
    
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit()
    else : args = parser.parse_args()
    
    return args

def get_data():
    # image resize
    my_transform = transforms.Compose([
        transforms.Resize([32, 32]),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (1.0,))
    ])
    download_root = "./MNIST/mnist_dataset"
    train_dataset = MNIST(download_root, 
                          transform = my_transform,
                          train = True,
                          download = args.download)
    eval_dataset = MNIST(download_root, 
                          transform = my_transform,
                          train = False,
                          download = args.download)
    test_dataset = MNIST(download_root, 
                        transform = my_transform,
                        train = False,
                        download = args.download)

def main():
    print(torch.__version__)
    if torch.cuda.is_available():
        print("gpu")
        device = torch.device("cuda")
    else:
        print("cpu")
        device = torch.device("cuda")
    
    # get MNIST data set
    train_dataset, eval_dataset, test_dataset = get_data()

if __name__ == '__main__':
    args = parse_args()
    main()
```
